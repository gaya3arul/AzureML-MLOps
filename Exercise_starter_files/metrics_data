{"f1796d2c-1419-42c3-a1df-01909ac46f92_22":{},"f1796d2c-1419-42c3-a1df-01909ac46f92_20":{},"f1796d2c-1419-42c3-a1df-01909ac46f92_16":{"norm_macro_recall":[0.4888987436935784],"AUC_weighted":[0.8474451088651611],"average_precision_score_weighted":[0.9154962669998217],"precision_score_micro":[0.768679817905918],"AUC_macro":[0.8474451088651609],"average_precision_score_micro":[0.8096180452635501],"f1_score_macro":[0.6336840039065141],"balanced_accuracy":[0.744449371846789],"recall_score_macro":[0.744449371846789],"precision_score_weighted":[0.8813713810407078],"average_precision_score_macro":[0.7118147404441533],"weighted_accuracy":[0.7746027794452687],"matthews_correlation":[0.3476408724192598],"recall_score_micro":[0.768679817905918],"recall_score_weighted":[0.768679817905918],"precision_score_macro":[0.6240768085836956],"f1_score_weighted":[0.8057979387055964],"AUC_micro":[0.8415102203412077],"accuracy":[0.768679817905918],"f1_score_micro":[0.7686798179059181],"log_loss":[0.5061374100032111]},"f1796d2c-1419-42c3-a1df-01909ac46f92_14":{"log_loss":[0.2612152344406157],"average_precision_score_macro":[0.7409501421750395],"f1_score_weighted":[0.8402180865524199],"average_precision_score_micro":[0.9650421576032372],"precision_score_macro":[0.690950945982787],"precision_score_micro":[0.8894688922610016],"f1_score_macro":[0.4902342339702801],"recall_score_micro":[0.8894688922610016],"average_precision_score_weighted":[0.9284989975202249],"matthews_correlation":[0.08230035413929167],"recall_score_weighted":[0.8894688922610016],"AUC_macro":[0.8863912731440606],"weighted_accuracy":[0.9837639501043884],"AUC_micro":[0.9649178343054382],"accuracy":[0.8894688922610016],"norm_macro_recall":[0.019930255249164208],"precision_score_weighted":[0.8453469983756573],"balanced_accuracy":[0.509965127624582],"recall_score_macro":[0.509965127624582],"f1_score_micro":[0.8894688922610016],"AUC_weighted":[0.8863912731440606]},"f1796d2c-1419-42c3-a1df-01909ac46f92_0":{"recall_score_weighted":[0.9144157814871017],"norm_macro_recall":[0.5037139284731673],"average_precision_score_macro":[0.8262948541138542],"average_precision_score_micro":[0.9818902825827353],"precision_score_micro":[0.9144157814871017],"recall_score_micro":[0.9144157814871017],"f1_score_macro":[0.7695433632192865],"AUC_micro":[0.9810792321100854],"weighted_accuracy":[0.9548042339535432],"recall_score_macro":[0.7518569642365837],"f1_score_weighted":[0.9113127087657691],"f1_score_micro":[0.9144157814871017],"precision_score_macro":[0.7914212857326756],"AUC_weighted":[0.9489629240236944],"balanced_accuracy":[0.7518569642365837],"accuracy":[0.9144157814871017],"log_loss":[0.17259344664205858],"matthews_correlation":[0.5417959465994486],"AUC_macro":[0.9489629240236944],"average_precision_score_weighted":[0.9559770226907679],"precision_score_weighted":[0.9092869525277483]},"f1796d2c-1419-42c3-a1df-01909ac46f92_3":{"precision_score_weighted":[0.8944590666848393],"log_loss":[0.4887379356034523],"average_precision_score_weighted":[0.9311307321335616],"f1_score_macro":[0.6704456458356479],"average_precision_score_micro":[0.8707943952312313],"weighted_accuracy":[0.8038255948591628],"recall_score_macro":[0.7872808385477276],"AUC_weighted":[0.8891300006624074],"precision_score_macro":[0.648683993839311],"matthews_correlation":[0.4132564949078539],"norm_macro_recall":[0.5745616770954551],"AUC_macro":[0.8891300006624074],"precision_score_micro":[0.800576631259484],"average_precision_score_macro":[0.7461731725837512],"f1_score_micro":[0.800576631259484],"balanced_accuracy":[0.7872808385477276],"recall_score_weighted":[0.800576631259484],"recall_score_micro":[0.800576631259484],"AUC_micro":[0.8838737361293724],"accuracy":[0.800576631259484],"f1_score_weighted":[0.8310522114504117]},"f1796d2c-1419-42c3-a1df-01909ac46f92_17":{"average_precision_score_macro":[0.7030799318774372],"AUC_macro":[0.8173016070496842],"precision_score_macro":[0.6110514950284504],"f1_score_macro":[0.6170191376794673],"f1_score_micro":[0.7527162367223066],"f1_score_weighted":[0.7938692742088599],"recall_score_macro":[0.730498957277399],"weighted_accuracy":[0.7582455641290531],"accuracy":[0.7527162367223066],"recall_score_weighted":[0.7527162367223066],"log_loss":[0.5605755551489098],"precision_score_weighted":[0.8761970173154559],"recall_score_micro":[0.7527162367223066],"balanced_accuracy":[0.730498957277399],"precision_score_micro":[0.7527162367223066],"average_precision_score_micro":[0.8150203205476302],"matthews_correlation":[0.3199416259382195],"average_precision_score_weighted":[0.9087097978397413],"AUC_weighted":[0.8173016070496841],"AUC_micro":[0.8407846670703991],"norm_macro_recall":[0.4609979145547981]},"f1796d2c-1419-42c3-a1df-01909ac46f92_23":{"AUC_weighted":[0.9429486565328418],"norm_macro_recall":[0.47689945998851313],"precision_score_micro":[0.9091957511380879],"log_loss":[0.19506145120903937],"f1_score_macro":[0.7553488095700738],"balanced_accuracy":[0.7384497299942565],"average_precision_score_micro":[0.9798445341218736],"precision_score_macro":[0.7763979479570328],"AUC_macro":[0.942948656657383],"accuracy":[0.9091957511380879],"precision_score_weighted":[0.9036572754379346],"average_precision_score_weighted":[0.9513545434547119],"AUC_micro":[0.9789114191042205],"average_precision_score_macro":[0.8083972791795159],"weighted_accuracy":[0.9516088933338047],"f1_score_micro":[0.9091957511380879],"matthews_correlation":[0.5133919723947867],"recall_score_macro":[0.7384497299942565],"recall_score_micro":[0.9091957511380879],"f1_score_weighted":[0.9058901813449696],"recall_score_weighted":[0.9091957511380879]},"f1796d2c-1419-42c3-a1df-01909ac46f92_18":{"recall_score_micro":[0.7298937784522004],"matthews_correlation":[0.33591865725185505],"AUC_macro":[0.8673714235558613],"precision_score_macro":[0.6124673803596088],"precision_score_micro":[0.7298937784522004],"AUC_micro":[0.8512161480700284],"recall_score_weighted":[0.7298937784522004],"f1_score_micro":[0.7298937784522004],"balanced_accuracy":[0.7508438972941093],"average_precision_score_macro":[0.7250375283132858],"average_precision_score_micro":[0.8592085325821068],"average_precision_score_weighted":[0.9235075886969115],"AUC_weighted":[0.8673714235558613],"f1_score_macro":[0.6092474359887581],"precision_score_weighted":[0.884214941143782],"norm_macro_recall":[0.5016877945882185],"log_loss":[0.5572159724074494],"f1_score_weighted":[0.7776727758618266],"weighted_accuracy":[0.7246976963789751],"recall_score_macro":[0.7508438972941093],"accuracy":[0.7298937784522004]},"f1796d2c-1419-42c3-a1df-01909ac46f92_21":{"norm_macro_recall":[0.4026560342633031],"f1_score_macro":[0.7337547173749733],"average_precision_score_macro":[0.8101568035116866],"precision_score_macro":[0.7874141910957511],"f1_score_weighted":[0.9016367967041793],"recall_score_micro":[0.9095599393019727],"matthews_correlation":[0.48099960216969284],"AUC_weighted":[0.940058517872974],"average_precision_score_weighted":[0.951426666282717],"balanced_accuracy":[0.7013280171316515],"precision_score_micro":[0.9095599393019727],"recall_score_macro":[0.7013280171316515],"recall_score_weighted":[0.9095599393019727],"accuracy":[0.9095599393019727],"f1_score_micro":[0.9095599393019727],"weighted_accuracy":[0.9612730504559723],"log_loss":[0.1845815773775481],"AUC_macro":[0.940058517872974],"AUC_micro":[0.9783550005641508],"precision_score_weighted":[0.8990812110008995],"average_precision_score_micro":[0.9793092554286303]},"f1796d2c-1419-42c3-a1df-01909ac46f92_8":{"accuracy":[0.8879514415781486],"AUC_micro":[0.9661299665424],"f1_score_macro":[0.4703248283762755],"f1_score_weighted":[0.8352532264037464],"matthews_correlation":[0.0],"AUC_macro":[0.8928409199128794],"norm_macro_recall":[0.0],"log_loss":[0.2738139071851403],"AUC_weighted":[0.8928409199128794],"weighted_accuracy":[0.9843197680605863],"recall_score_micro":[0.8879514415781486],"precision_score_macro":[0.4439757207890743],"average_precision_score_weighted":[0.9286389856908507],"recall_score_macro":[0.5],"recall_score_weighted":[0.8879514415781486],"average_precision_score_macro":[0.7363293617450635],"precision_score_micro":[0.8879514415781486],"precision_score_weighted":[0.7884613418500925],"f1_score_micro":[0.8879514415781486],"average_precision_score_micro":[0.9665913436993249],"balanced_accuracy":[0.5]},"f1796d2c-1419-42c3-a1df-01909ac46f92_11":{"average_precision_score_macro":[0.7384828471575713],"precision_score_weighted":[0.9015138918378615],"precision_score_micro":[0.7282549317147193],"f1_score_weighted":[0.7774612794704683],"norm_macro_recall":[0.5949646602052615],"balanced_accuracy":[0.7974823301026308],"recall_score_micro":[0.7282549317147193],"average_precision_score_micro":[0.8729577052909183],"weighted_accuracy":[0.7110179186095582],"AUC_micro":[0.8616742569902897],"accuracy":[0.7282549317147193],"recall_score_macro":[0.7974823301026308],"AUC_weighted":[0.8831921913116233],"f1_score_macro":[0.6228519725432526],"log_loss":[0.47632974251250426],"AUC_macro":[0.8831921913116233],"average_precision_score_weighted":[0.9285526805756129],"recall_score_weighted":[0.7282549317147193],"matthews_correlation":[0.3922119617089074],"f1_score_micro":[0.7282549317147192],"precision_score_macro":[0.6292961408252715]},"f1796d2c-1419-42c3-a1df-01909ac46f92_19":{"average_precision_score_micro":[0.97629081935189],"log_loss":[0.2237751942302224],"precision_score_weighted":[0.8919158800606286],"average_precision_score_weighted":[0.9485067300261006],"recall_score_macro":[0.5882695105130582],"AUC_micro":[0.9753270394053619],"recall_score_micro":[0.9026707132018208],"weighted_accuracy":[0.9807644230728865],"f1_score_micro":[0.902670713201821],"accuracy":[0.9026707132018208],"recall_score_weighted":[0.9026707132018208],"average_precision_score_macro":[0.8006787495008048],"AUC_macro":[0.9346444067628303],"precision_score_macro":[0.8432987271643857],"AUC_weighted":[0.9346444067628303],"matthews_correlation":[0.34808236113336843],"f1_score_macro":[0.6221125551380587],"balanced_accuracy":[0.5882695105130582],"f1_score_weighted":[0.8747541424822736],"norm_macro_recall":[0.1765390210261164],"precision_score_micro":[0.9026707132018208]},"f1796d2c-1419-42c3-a1df-01909ac46f92_25":{"AUC_weighted":[0.9408119985130078],"norm_macro_recall":[0.0],"precision_score_macro":[0.4439757207890743],"f1_score_macro":[0.4703248283762755],"average_precision_score_macro":[0.8136998470974465],"log_loss":[0.2907621125621046],"AUC_micro":[0.9756630660793357],"accuracy":[0.8879514415781486],"AUC_macro":[0.9408119985130078],"f1_score_micro":[0.8879514415781486],"average_precision_score_micro":[0.9767095752127309],"weighted_accuracy":[0.9843197680605863],"f1_score_weighted":[0.8352532264037464],"recall_score_micro":[0.8879514415781486],"recall_score_weighted":[0.8879514415781486],"matthews_correlation":[0.0],"recall_score_macro":[0.5],"balanced_accuracy":[0.5],"average_precision_score_weighted":[0.9521240910606867],"precision_score_micro":[0.8879514415781486],"precision_score_weighted":[0.7884613418500925]},"f1796d2c-1419-42c3-a1df-01909ac46f92_9":{"f1_score_macro":[0.5996270226037577],"accuracy":[0.7311380880121396],"f1_score_micro":[0.7311380880121395],"recall_score_micro":[0.7311380880121396],"recall_score_macro":[0.7197409230575245],"f1_score_weighted":[0.7776687767317251],"AUC_macro":[0.8182005498030953],"precision_score_macro":[0.6014003231924316],"AUC_micro":[0.8341549687874901],"recall_score_weighted":[0.7311380880121396],"precision_score_weighted":[0.8732660156411616],"log_loss":[0.5524363524104506],"balanced_accuracy":[0.7197409230575245],"norm_macro_recall":[0.4394818461150489],"weighted_accuracy":[0.7339757657729928],"matthews_correlation":[0.2985254556017048],"average_precision_score_micro":[0.810116407883499],"AUC_weighted":[0.8182005498030953],"average_precision_score_weighted":[0.9100523912498211],"average_precision_score_macro":[0.704164504234317],"precision_score_micro":[0.7311380880121396]},"f1796d2c-1419-42c3-a1df-01909ac46f92_6":{"log_loss":[0.25331659083670083],"AUC_micro":[0.9659682647870849],"recall_score_weighted":[0.8997572078907435],"average_precision_score_weighted":[0.929621995680305],"f1_score_micro":[0.8997572078907435],"recall_score_micro":[0.8997572078907435],"recall_score_macro":[0.5837417135989433],"balanced_accuracy":[0.5837417135989433],"weighted_accuracy":[0.9782426761758348],"accuracy":[0.8997572078907435],"average_precision_score_macro":[0.7386474885930462],"precision_score_weighted":[0.88358617973494],"precision_score_macro":[0.8090303285529675],"matthews_correlation":[0.32156557828199134],"average_precision_score_micro":[0.967213328095345],"AUC_macro":[0.890048559133813],"precision_score_micro":[0.8997572078907435],"norm_macro_recall":[0.16748342719788661],"f1_score_weighted":[0.8717980873117556],"AUC_weighted":[0.890048559133813],"f1_score_macro":[0.6144151335945756]},"f1796d2c-1419-42c3-a1df-01909ac46f92_24":{"average_precision_score_macro":[0.8214100329108014],"matthews_correlation":[0.5353843209937456],"average_precision_score_micro":[0.9799962136707995],"precision_score_micro":[0.9155386949924129],"AUC_micro":[0.9796945111575225],"weighted_accuracy":[0.959400158219254],"f1_score_macro":[0.7641571354886769],"f1_score_weighted":[0.9107487723140842],"recall_score_weighted":[0.9155386949924129],"average_precision_score_weighted":[0.9537116682538367],"accuracy":[0.9155386949924129],"recall_score_micro":[0.9155386949924129],"AUC_weighted":[0.9428169790385095],"recall_score_macro":[0.7390698927235336],"f1_score_micro":[0.9155386949924129],"norm_macro_recall":[0.4781397854470672],"log_loss":[0.3161421717407235],"AUC_macro":[0.9428169790385095],"balanced_accuracy":[0.7390698927235336],"precision_score_weighted":[0.9087885872131221],"precision_score_macro":[0.8003831940668966]},"f1796d2c-1419-42c3-a1df-01909ac46f92_26":{"weighted_accuracy":[0.9437512879980605],"AUC_weighted":[0.9274075999824211],"f1_score_micro":[0.9050379362670713],"average_precision_score_macro":[0.7707072669782915],"accuracy":[0.9050379362670714],"precision_score_micro":[0.9050379362670714],"precision_score_macro":[0.7621526606396913],"recall_score_micro":[0.9050379362670714],"average_precision_score_weighted":[0.9398743342402162],"recall_score_macro":[0.7496579338158965],"precision_score_weighted":[0.9028716970109757],"average_precision_score_micro":[0.9740011846318032],"log_loss":[0.205943582290452],"matthews_correlation":[0.5109451796549739],"norm_macro_recall":[0.4993158676317931],"balanced_accuracy":[0.7496579338158965],"AUC_micro":[0.9751748706482669],"recall_score_weighted":[0.9050379362670714],"AUC_macro":[0.927407599982421],"f1_score_weighted":[0.9036226778804881],"f1_score_macro":[0.7546426581138407]},"f1796d2c-1419-42c3-a1df-01909ac46f92_10":{"average_precision_score_weighted":[0.9166670422067137],"recall_score_weighted":[0.7616995447647952],"matthews_correlation":[0.34268355618953894],"weighted_accuracy":[0.7658034707161387],"precision_score_micro":[0.7616995447647952],"norm_macro_recall":[0.4907507162779929],"balanced_accuracy":[0.7453753581389965],"recall_score_macro":[0.7453753581389965],"AUC_macro":[0.8511803980734536],"precision_score_macro":[0.619786231582313],"average_precision_score_micro":[0.8085536487461497],"AUC_weighted":[0.8511803980734536],"precision_score_weighted":[0.881337354619404],"log_loss":[0.5273037027627037],"f1_score_micro":[0.7616995447647952],"f1_score_weighted":[0.8007905336738412],"recall_score_micro":[0.7616995447647952],"AUC_micro":[0.8455725670706293],"average_precision_score_macro":[0.7048713099674628],"f1_score_macro":[0.6281227135740926],"accuracy":[0.7616995447647952]},"f1796d2c-1419-42c3-a1df-01909ac46f92_12":{"recall_score_micro":[0.7501669195751138],"AUC_micro":[0.8505513020371603],"recall_score_weighted":[0.7501669195751138],"average_precision_score_macro":[0.7112088464892954],"f1_score_weighted":[0.7922007604725986],"AUC_weighted":[0.8570518009829122],"recall_score_macro":[0.7368314920896019],"precision_score_micro":[0.7501669195751138],"log_loss":[0.5831274118889584],"f1_score_micro":[0.7501669195751138],"balanced_accuracy":[0.7368314920896019],"precision_score_macro":[0.6142762092403344],"precision_score_weighted":[0.8787952003005468],"average_precision_score_weighted":[0.9188182583390707],"average_precision_score_micro":[0.8401155030689089],"norm_macro_recall":[0.47366298417920377],"AUC_macro":[0.8570518009829122],"matthews_correlation":[0.32871834156614976],"accuracy":[0.7501669195751138],"weighted_accuracy":[0.7535015705512471],"f1_score_macro":[0.618587583086206]},"f1796d2c-1419-42c3-a1df-01909ac46f92_15":{"recall_score_micro":[0.8879514415781486],"accuracy":[0.8879514415781486],"recall_score_macro":[0.5],"average_precision_score_macro":[0.6989083850288805],"f1_score_macro":[0.4703248283762755],"weighted_accuracy":[0.9843197680605863],"recall_score_weighted":[0.8879514415781486],"AUC_micro":[0.9643253239262137],"log_loss":[0.2553797645629172],"precision_score_micro":[0.8879514415781486],"average_precision_score_weighted":[0.9194438444132107],"precision_score_weighted":[0.7884613418500925],"f1_score_micro":[0.8879514415781486],"AUC_macro":[0.8839600252738873],"average_precision_score_micro":[0.9643401574532044],"norm_macro_recall":[0.0],"f1_score_weighted":[0.8352532264037464],"AUC_weighted":[0.8839600252738873],"precision_score_macro":[0.4439757207890743],"balanced_accuracy":[0.5],"matthews_correlation":[0.0]},"f1796d2c-1419-42c3-a1df-01909ac46f92_5":{"AUC_macro":[0.9108179862255124],"weighted_accuracy":[0.9768462330464882],"recall_score_weighted":[0.899453717754173],"recall_score_micro":[0.899453717754173],"f1_score_micro":[0.899453717754173],"log_loss":[0.23291643414740099],"f1_score_weighted":[0.872753394598111],"precision_score_weighted":[0.8821040342767625],"balanced_accuracy":[0.5879381532524707],"f1_score_macro":[0.6196131025956708],"average_precision_score_weighted":[0.9340769194313208],"precision_score_micro":[0.899453717754173],"AUC_weighted":[0.9108179862255122],"average_precision_score_micro":[0.9708388215116998],"accuracy":[0.899453717754173],"average_precision_score_macro":[0.7482553792689888],"precision_score_macro":[0.799219102202201],"norm_macro_recall":[0.17587630650494127],"AUC_micro":[0.9700856588245859],"recall_score_macro":[0.5879381532524707],"matthews_correlation":[0.32410521050135827]},"f1796d2c-1419-42c3-a1df-01909ac46f92_7":{"f1_score_micro":[0.8894081942336873],"precision_score_weighted":[0.8774900822891276],"recall_score_macro":[0.5092447140559953],"accuracy":[0.8894081942336873],"balanced_accuracy":[0.5092447140559953],"f1_score_weighted":[0.8400598212389655],"norm_macro_recall":[0.018489428111990457],"recall_score_micro":[0.8894081942336873],"recall_score_weighted":[0.8894081942336873],"precision_score_macro":[0.835131159439913],"AUC_macro":[0.8429211237650843],"weighted_accuracy":[0.9838210213722502],"average_precision_score_weighted":[0.9152892573948922],"average_precision_score_macro":[0.7118661055007672],"AUC_micro":[0.956217508940064],"precision_score_micro":[0.8894081942336873],"log_loss":[0.2786313304085769],"AUC_weighted":[0.8429211237650842],"average_precision_score_micro":[0.9549364538487431],"matthews_correlation":[0.10134943094919442],"f1_score_macro":[0.48923879008358745]},"f1796d2c-1419-42c3-a1df-01909ac46f92_4":{"AUC_macro":[0.8913350073371079],"recall_score_micro":[0.8879514415781486],"log_loss":[0.2627399279447058],"matthews_correlation":[0.0],"precision_score_weighted":[0.7884613418500925],"f1_score_micro":[0.8879514415781486],"AUC_weighted":[0.8913350073371079],"AUC_micro":[0.9658227046543596],"average_precision_score_macro":[0.7223814065236256],"recall_score_macro":[0.5],"accuracy":[0.8879514415781486],"average_precision_score_micro":[0.9665381046110009],"f1_score_macro":[0.4703248283762755],"precision_score_macro":[0.4439757207890743],"norm_macro_recall":[0.0],"balanced_accuracy":[0.5],"precision_score_micro":[0.8879514415781486],"average_precision_score_weighted":[0.925567217487903],"recall_score_weighted":[0.8879514415781486],"weighted_accuracy":[0.9843197680605863],"f1_score_weighted":[0.8352532264037464]},"f1796d2c-1419-42c3-a1df-01909ac46f92_1":{"weighted_accuracy":[0.9599396217892462],"precision_score_weighted":[0.9074494120258981],"f1_score_macro":[0.7606149023199388],"balanced_accuracy":[0.7336577332358241],"AUC_weighted":[0.9469943280414782],"average_precision_score_micro":[0.9814408813866381],"average_precision_score_weighted":[0.9559275656602093],"precision_score_micro":[0.9149317147192717],"recall_score_weighted":[0.9149317147192717],"AUC_macro":[0.9469943283657603],"AUC_micro":[0.9806089467418561],"f1_score_micro":[0.9149317147192717],"recall_score_macro":[0.7336577332358241],"f1_score_weighted":[0.909767316524621],"average_precision_score_macro":[0.8270301995665266],"accuracy":[0.9149317147192717],"precision_score_macro":[0.798786649757224],"norm_macro_recall":[0.4673154664716481],"matthews_correlation":[0.5283949538267647],"log_loss":[0.17680045066468897],"recall_score_micro":[0.9149317147192717]},"f1796d2c-1419-42c3-a1df-01909ac46f92_13":{"accuracy":[0.9132018209408195],"AUC_macro":[0.9363012475203197],"average_precision_score_micro":[0.9775201365831443],"f1_score_weighted":[0.9069692475325486],"f1_score_macro":[0.7513317602193598],"precision_score_macro":[0.7973952001665008],"f1_score_micro":[0.9132018209408195],"average_precision_score_macro":[0.8144216263767621],"weighted_accuracy":[0.9602502413061001],"recall_score_macro":[0.723911951346805],"recall_score_weighted":[0.9132018209408195],"average_precision_score_weighted":[0.9507269012844294],"norm_macro_recall":[0.4478239026936099],"precision_score_micro":[0.9132018209408195],"AUC_weighted":[0.9363012475203197],"AUC_micro":[0.9780340793173083],"log_loss":[0.3198805952638328],"balanced_accuracy":[0.723911951346805],"matthews_correlation":[0.5143036428922769],"precision_score_weighted":[0.9054311834096799],"recall_score_micro":[0.9132018209408195]},"f1796d2c-1419-42c3-a1df-01909ac46f92_29":{"AUC_macro":[0.9412404565314325],"weighted_accuracy":[0.9614246669331801],"average_precision_score_macro":[0.8111242232916174],"f1_score_weighted":[0.9021953616399385],"norm_macro_recall":[0.40603410384930994],"AUC_weighted":[0.9412404565314325],"accuracy":[0.9100151745068285],"precision_score_macro":[0.7889687584691727],"average_precision_score_weighted":[0.951743257497631],"log_loss":[0.18355121684098458],"balanced_accuracy":[0.703017051924655],"recall_score_micro":[0.9100151745068285],"recall_score_weighted":[0.9100151745068285],"f1_score_macro":[0.7354130913409023],"f1_score_micro":[0.9100151745068285],"recall_score_macro":[0.703017051924655],"precision_score_micro":[0.9100151745068285],"matthews_correlation":[0.48425669417915235],"AUC_micro":[0.9786819916137247],"average_precision_score_micro":[0.97958655142937],"precision_score_weighted":[0.8997230196559511]},"f1796d2c-1419-42c3-a1df-01909ac46f92_27":{"accuracy":[0.8879514415781486],"balanced_accuracy":[0.5],"f1_score_weighted":[0.8352532264037464],"AUC_macro":[0.9093258645848916],"norm_macro_recall":[0.0],"recall_score_micro":[0.8879514415781486],"weighted_accuracy":[0.9843197680605863],"precision_score_micro":[0.8879514415781486],"f1_score_micro":[0.8879514415781486],"average_precision_score_micro":[0.9707785205623368],"AUC_weighted":[0.9093258645848916],"precision_score_macro":[0.4439757207890743],"average_precision_score_weighted":[0.9342232589730918],"log_loss":[0.23406933926126833],"average_precision_score_macro":[0.7484404077919248],"AUC_micro":[0.9693993474271266],"recall_score_macro":[0.5],"f1_score_macro":[0.4703248283762755],"precision_score_weighted":[0.7884613418500925],"matthews_correlation":[0.0],"recall_score_weighted":[0.8879514415781486]},"f1796d2c-1419-42c3-a1df-01909ac46f92_2":{"log_loss":[0.2353883516568478],"recall_score_macro":[0.538233013369329],"AUC_micro":[0.9695634899984112],"precision_score_micro":[0.894112291350531],"matthews_correlation":[0.19423786999003104],"AUC_macro":[0.909446836041403],"average_precision_score_macro":[0.7603816391006386],"balanced_accuracy":[0.538233013369329],"average_precision_score_micro":[0.9704837196621441],"recall_score_micro":[0.894112291350531],"weighted_accuracy":[0.9826114832251578],"f1_score_micro":[0.894112291350531],"f1_score_weighted":[0.8529723179768123],"norm_macro_recall":[0.07646602673865818],"recall_score_weighted":[0.894112291350531],"accuracy":[0.894112291350531],"f1_score_macro":[0.5399583893622564],"precision_score_weighted":[0.8782147460670009],"AUC_weighted":[0.9094468360414032],"average_precision_score_weighted":[0.9364278907955498],"precision_score_macro":[0.8180005407630351]},"f1796d2c-1419-42c3-a1df-01909ac46f92_31":{"recall_score_macro":[0.7388231952492773],"f1_score_micro":[0.9144157814871017],"norm_macro_recall":[0.4776463904985544],"precision_score_micro":[0.9144157814871017],"precision_score_weighted":[0.9075942039454207],"AUC_micro":[0.9806086174619659],"f1_score_weighted":[0.9099304080362061],"average_precision_score_weighted":[0.9552705837981936],"accuracy":[0.9144157814871017],"AUC_macro":[0.9473553432526473],"average_precision_score_macro":[0.8238606045086326],"weighted_accuracy":[0.958014545558861],"matthews_correlation":[0.5307129670353303],"AUC_weighted":[0.9473553521806461],"log_loss":[0.1759132722495138],"average_precision_score_micro":[0.9814441394326281],"precision_score_macro":[0.7949125292665838],"recall_score_weighted":[0.9144157814871017],"balanced_accuracy":[0.7388231952492773],"f1_score_macro":[0.762649061879769],"recall_score_micro":[0.9144157814871017]},"f1796d2c-1419-42c3-a1df-01909ac46f92_33":{"accuracy":[0.9123520485584218],"recall_score_micro":[0.9123520485584218],"AUC_macro":[0.9454281451071379],"recall_score_weighted":[0.9123520485584218],"log_loss":[0.18367829322750634],"f1_score_micro":[0.9123520485584219],"AUC_weighted":[0.9454281455489847],"precision_score_micro":[0.9123520485584218],"f1_score_weighted":[0.9094673186057326],"f1_score_macro":[0.765432198337409],"precision_score_macro":[0.7847701400851697],"average_precision_score_micro":[0.9806539003127839],"matthews_correlation":[0.5330846379738065],"AUC_micro":[0.9797872437431063],"balanced_accuracy":[0.7495162049592209],"recall_score_macro":[0.7495162049592209],"weighted_accuracy":[0.9528103979380587],"average_precision_score_macro":[0.8157789221864158],"precision_score_weighted":[0.9074655136252746],"norm_macro_recall":[0.49903240991844183],"average_precision_score_weighted":[0.9532351005408538]},"f1796d2c-1419-42c3-a1df-01909ac46f92_28":{"balanced_accuracy":[0.5],"AUC_micro":[0.970638029294397],"AUC_macro":[0.915549864088305],"AUC_weighted":[0.9155498640883047],"average_precision_score_micro":[0.9719837505812212],"precision_score_macro":[0.4439757207890743],"weighted_accuracy":[0.9843197680605863],"precision_score_micro":[0.8879514415781486],"f1_score_weighted":[0.8352532264037464],"f1_score_micro":[0.8879514415781486],"accuracy":[0.8879514415781486],"average_precision_score_macro":[0.7669826484467173],"recall_score_micro":[0.8879514415781486],"log_loss":[0.22166565193030685],"recall_score_macro":[0.5],"matthews_correlation":[0.0],"norm_macro_recall":[0.0],"precision_score_weighted":[0.7884613418500925],"f1_score_macro":[0.4703248283762755],"average_precision_score_weighted":[0.9390883273178371],"recall_score_weighted":[0.8879514415781486]},"f1796d2c-1419-42c3-a1df-01909ac46f92_30":{"log_loss":[0.2865431938900354],"recall_score_weighted":[0.8879514415781486],"AUC_micro":[0.9704783676928072],"precision_score_macro":[0.4439757207890743],"weighted_accuracy":[0.9843197680605863],"accuracy":[0.8879514415781486],"AUC_macro":[0.9147624842534657],"precision_score_micro":[0.8879514415781486],"average_precision_score_micro":[0.9716495747551612],"average_precision_score_weighted":[0.9352139534229135],"matthews_correlation":[0.0],"f1_score_macro":[0.4703248283762755],"norm_macro_recall":[0.0],"precision_score_weighted":[0.7884613418500925],"balanced_accuracy":[0.5],"AUC_weighted":[0.9147624842534657],"average_precision_score_macro":[0.7506942295051006],"f1_score_weighted":[0.8352532264037464],"recall_score_macro":[0.5],"f1_score_micro":[0.8879514415781486],"recall_score_micro":[0.8879514415781486]},"f1796d2c-1419-42c3-a1df-01909ac46f92_32":{"recall_score_macro":[0.7412207788228339],"f1_score_weighted":[0.9110977789162409],"average_precision_score_micro":[0.9813878436246813],"norm_macro_recall":[0.4824415576456679],"accuracy":[0.9155690440060699],"average_precision_score_weighted":[0.9553986152623756],"f1_score_macro":[0.7656196956703816],"balanced_accuracy":[0.7412207788228339],"weighted_accuracy":[0.9588517151473013],"precision_score_micro":[0.9155690440060699],"precision_score_macro":[0.79877260961434],"precision_score_weighted":[0.9088483075527469],"recall_score_micro":[0.9155690440060699],"log_loss":[0.17594903195867478],"matthews_correlation":[0.5368440120088736],"AUC_micro":[0.9805674805022555],"AUC_weighted":[0.9469404464933833],"f1_score_micro":[0.9155690440060699],"AUC_macro":[0.946940446493383],"average_precision_score_macro":[0.8247616910865428],"recall_score_weighted":[0.9155690440060699]},"f1796d2c-1419-42c3-a1df-01909ac46f92_36":{"average_precision_score_macro":[0.8244745857224229],"f1_score_micro":[0.9146282245827011],"precision_score_micro":[0.9146282245827011],"AUC_weighted":[0.9468142706575382],"matthews_correlation":[0.533658354807832],"f1_score_macro":[0.7642849834139337],"weighted_accuracy":[0.957718119679414],"precision_score_macro":[0.7953857210131632],"recall_score_macro":[0.741119335930744],"AUC_micro":[0.9804939290459403],"f1_score_weighted":[0.9103572284088577],"average_precision_score_weighted":[0.9553056504757796],"AUC_macro":[0.9468142706575382],"average_precision_score_micro":[0.9813021813032126],"norm_macro_recall":[0.48223867186148794],"precision_score_weighted":[0.9081056422657063],"recall_score_micro":[0.9146282245827011],"balanced_accuracy":[0.741119335930744],"accuracy":[0.9146282245827011],"recall_score_weighted":[0.9146282245827011],"log_loss":[0.17576222618911316]},"f1796d2c-1419-42c3-a1df-01909ac46f92_39":{"norm_macro_recall":[0.4883703173234409],"accuracy":[0.9163884673748102],"AUC_weighted":[0.9498964691131226],"weighted_accuracy":[0.9591686340671233],"average_precision_score_macro":[0.83069029431991],"balanced_accuracy":[0.7441851586617204],"f1_score_macro":[0.7683834850206234],"average_precision_score_weighted":[0.9570556990057313],"precision_score_macro":[0.8012936967295076],"recall_score_micro":[0.9163884673748102],"AUC_micro":[0.9813985184707598],"precision_score_micro":[0.9163884673748102],"matthews_correlation":[0.5423385230037101],"recall_score_weighted":[0.9163884673748102],"recall_score_macro":[0.7441851586617204],"f1_score_weighted":[0.9120435204122492],"AUC_macro":[0.9498964691131226],"average_precision_score_micro":[0.9821892724231184],"f1_score_micro":[0.9163884673748102],"log_loss":[0.19220159834891262],"precision_score_weighted":[0.9099165585029949]},"f1796d2c-1419-42c3-a1df-01909ac46f92_38":{"matthews_correlation":[0.5435925828601351],"average_precision_score_macro":[0.8308224714262519],"average_precision_score_micro":[0.982270284461088],"recall_score_micro":[0.9159332321699545],"AUC_weighted":[0.9500943224741609],"precision_score_macro":[0.7981654520925592],"precision_score_micro":[0.9159332321699545],"norm_macro_recall":[0.4956453345217556],"recall_score_weighted":[0.9159332321699545],"AUC_micro":[0.9814816121359211],"AUC_macro":[0.9500943224741608],"f1_score_macro":[0.7696459378610487],"f1_score_micro":[0.9159332321699545],"weighted_accuracy":[0.9576930338825557],"average_precision_score_weighted":[0.9571090824570797],"f1_score_weighted":[0.9120791518570851],"accuracy":[0.9159332321699545],"log_loss":[0.18568547354041756],"recall_score_macro":[0.7478226672608779],"balanced_accuracy":[0.7478226672608779],"precision_score_weighted":[0.9099341720688645]},"f1796d2c-1419-42c3-a1df-01909ac46f92_35":{"log_loss":[0.21194982073863472],"f1_score_micro":[0.9064643399089529],"matthews_correlation":[0.39940573324034256],"f1_score_weighted":[0.8856061864071479],"average_precision_score_weighted":[0.949713159385946],"average_precision_score_micro":[0.9774361023477198],"weighted_accuracy":[0.9770638910491328],"f1_score_macro":[0.6646378756610922],"precision_score_micro":[0.9064643399089529],"recall_score_macro":[0.6222244121021456],"recall_score_micro":[0.9064643399089529],"average_precision_score_macro":[0.8054088165293416],"AUC_micro":[0.9765014172851219],"recall_score_weighted":[0.9064643399089529],"norm_macro_recall":[0.24444882420429126],"AUC_weighted":[0.9355982642269831],"precision_score_weighted":[0.8938942604512412],"accuracy":[0.9064643399089529],"precision_score_macro":[0.8267823509330811],"balanced_accuracy":[0.6222244121021456],"AUC_macro":[0.9355982642269831]}}